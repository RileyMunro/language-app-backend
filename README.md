# Language Learning App - Backend

A FastAPI-based backend for generating Vietnamese language learning questions using AI. The app uses known words and grammar points to create personalized multiple-choice quiz questions.

## Features

- ğŸ“š Store and manage Vietnamese vocabulary with English definitions
- ğŸ“ Track grammar points with explanations and examples
- ğŸ¤– Generate AI-powered quiz questions using OpenAI
- ğŸ³ Docker-ready with Poetry for dependency management
- âœ… Fully typed with mypy and tested with pytest
- ğŸ—„ï¸ SQLite database with async SQLAlchemy

## Tech Stack

- **FastAPI** - Modern, fast web framework
- **SQLAlchemy 2.0** - Async ORM
- **OpenAI API** - Question generation
- **Poetry** - Dependency management
- **Docker** - Containerization
- **Pydantic** - Data validation
- **pytest** - Testing

## Setup

### Prerequisites

- Python 3.11+
- Poetry
- Docker & Docker Compose (for containerized deployment)
- OpenAI API key

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/RileyMunro/language-app-backend.git
cd backend
```

2. **Install dependencies:**
```bash
poetry install
```

3. **Create `.env` file:**
```bash
OPENAI_API_KEY=your-openai-api-key-here
DATABASE_URL=sqlite+aiosqlite:///./app.db
```

4. **Seed the database (optional):**
```bash
poetry run python -m app.db_seeder
```

This will populate the database with 95+ Vietnamese words and 23 grammar points.

## Running the App

### Using Docker (Recommended)
```bash
docker-compose up --build
```

The API will be available at `http://localhost:8001`

### Using Poetry (Local Development)
```bash
poetry run uvicorn app.main:app --reload
```

The API will be available at `http://localhost:8000`

## API Documentation

Once running, visit:
- **Swagger UI**: `http://localhost:8001/docs`
- **ReDoc**: `http://localhost:8001/redoc`

## API Endpoints

### Words

#### Add a Word
```bash
POST /api/v1/words
```
```json
{
  "vietnamese_word": "xin chÃ o",
  "english_definition": "hello"
}
```

#### List All Words
```bash
GET /api/v1/words
```

#### Get Specific Word
```bash
GET /api/v1/words/{word_id}
```

### Grammar

#### Add Grammar Point
```bash
POST /api/v1/grammar
```
```json
{
  "grammar_point": "pháº£i khÃ´ng",
  "english_explanation": "Tag question meaning 'right?'",
  "example_sentence": "Em lÃ  ngÆ°á»i Má»¹, pháº£i khÃ´ng?"
}
```

Note: `example_sentence` is optional.

#### List All Grammar
```bash
GET /api/v1/grammar
```

#### Get Specific Grammar Point
```bash
GET /api/v1/grammar/{grammar_id}
```

### Question Generation

#### Generate Questions
```bash
POST /api/v1/generate-questions
```
```json
{
  "num_questions": 5,
  "difficulty": "medium"
}
```

**Parameters:**
- `num_questions` (optional): Number of questions (1-20, default: 5)
- `difficulty` (optional): "easy", "medium", or "hard"

**Response:**
```json
{
  "questions": [
    {
      "question_type": 1,
      "question": "What does 'xin chÃ o' mean?",
      "answers": ["hello", "goodbye", "thank you", "please"],
      "correct_idx": 0
    }
  ]
}
```

## Development

### Running Tests
```bash
poetry run pytest
```

**With coverage:**
```bash
poetry run pytest --cov=app
```

**Verbose output:**
```bash
poetry run pytest -v
```

### Type Checking
```bash
poetry run mypy app/
```

### Code Structure
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Settings/configuration
â”‚   â”œâ”€â”€ database.py          # Database setup
â”‚   â”œâ”€â”€ models.py            # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py           # Pydantic schemas
â”‚   â”œâ”€â”€ routes.py            # API endpoints
â”‚   â”œâ”€â”€ openai_service.py    # OpenAI integration
â”‚   â””â”€â”€ db_seeder.py         # Database seeding script
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py          # Pytest fixtures
â”‚   â”œâ”€â”€ test_words.py
â”‚   â”œâ”€â”€ test_grammar.py
â”‚   â”œâ”€â”€ test_questions.py
â”‚   â””â”€â”€ test_health.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

### Adding New Words/Grammar

**Option 1: Via API (Swagger UI)**
1. Navigate to `http://localhost:8001/docs`
2. Use the POST endpoints to add data interactively

**Option 2: Via curl**
```bash
# Add a word
curl -X POST "http://localhost:8001/api/v1/words" \
  -H "Content-Type: application/json" \
  -d '{"vietnamese_word": "cáº£m Æ¡n", "english_definition": "thank you"}'

# Add grammar
curl -X POST "http://localhost:8001/api/v1/grammar" \
  -H "Content-Type: application/json" \
  -d '{
    "grammar_point": "KhÃ´ng sao",
    "english_explanation": "Expression meaning no problem",
    "example_sentence": "KhÃ´ng sao Ä‘Ã¢u!"
  }'
```

**Option 3: Bulk Seed**

Edit `app/db_seeder.py` to add your words/grammar to the `WORDS` and `GRAMMAR` lists, then run:
```bash
poetry run python -m app.db_seeder
```

### Resetting the Database
```bash
rm app.db
poetry run python -m app.db_seeder
```

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Your OpenAI API key | Required |
| `DATABASE_URL` | Database connection string | `sqlite+aiosqlite:///./app.db` |

## Docker

### Build Image
```bash
docker-compose build
```

### View Logs
```bash
docker-compose logs -f
```

### Stop Services
```bash
docker-compose down
```

## Language Focus

This app is specifically designed for **Southern Vietnamese dialect**. The vocabulary and grammar patterns reflect conversational Southern Vietnamese usage.

## License

MIT

## Contact

Riley Munro - riley.munro@gmail.com

## Acknowledgments

- README documentation generated with assistance from Claude (Anthropic)
- OpenAI for question generation API
